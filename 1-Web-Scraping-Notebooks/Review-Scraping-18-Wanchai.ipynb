{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "import matplotlib\n",
    "matplotlib.rcParams['figure.figsize'] = (30,20)\n",
    "import time\n",
    "from selenium.common.exceptions import TimeoutException\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.common.by import By\n",
    "import csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Wan Chai: Japanese "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cats' eye\n",
      "sando b\n",
      "Matsubishi Japanese Restaurant\n",
      "Matsubishi Japanese Restaurant\n",
      "Koku Ryu Ramen\n",
      "Ebisoba Ichigen\n",
      "RAKU\n",
      "Fuunmaru\n",
      "Matsubishi Japanese Restaurant\n",
      "VIA Tokyo x Yamataka\n",
      "Yamataka Seafood Market\n",
      "Rokkaku\n",
      "L16\n",
      "Kaetsu\n",
      "Fishman Fukuoka\n",
      "Torihana Tei Ramen\n",
      "Ebisoba Ichigen\n",
      "Fishman Fukuoka\n",
      "Mizuki Japanese Restaurant\n",
      "Yamataka Seafood Market\n",
      "Fishman Fukuoka\n",
      "Ebisoba Ichigen\n",
      "Ebisoba Ichigen\n",
      "The Yuu Japanese Dining\n",
      "Cats' eye\n",
      "Uohachi Japanese Restaurant\n",
      "Mizuki Japanese Restaurant\n",
      "Ebisoba Ichigen\n",
      "Cats' eye\n",
      "Ba Sushi Japanese Restaurant\n",
      "Sushi Jun\n",
      "Jan Jan Kushikatsu\n",
      "Rokkaku\n",
      "Ramen Shinbusakiya\n",
      "Fuunmaru\n",
      "33. Kyoto\n",
      "Torihana Tei Ramen\n",
      "Kafulin Gallery\n",
      "Kimaki Japanese Restaurant\n",
      "33. Kyoto\n",
      "Fuunmaru\n",
      "Jan Jan Kushikatsu\n",
      "Fuunmaru\n",
      "Fuunmaru\n",
      "Yamataka Seafood Market\n",
      "Fuunmaru\n",
      "Crystal Sky\n",
      "Ruto\n",
      "Ruto\n",
      "Sushitsuru\n",
      "Yamataka Seafood Market\n",
      "Friends Sushi Japanese Restaurant\n",
      "Toyosu Suisan\n",
      "Yamataka Seafood Market\n",
      "DJAPA\n",
      "Teppei Syokudo\n",
      "Ramen Shinbusakiya\n",
      " CHIRASHI\n",
      "Cats' eye\n",
      "Sakuragi Omakase\n",
      " CHIRASHI\n",
      "Toyosu Suisan\n",
      "Toyosu Suisan\n",
      "Akita Teppanyaki, Sashimi\n",
      "Koku Ryu Ramen\n",
      "Akita Teppanyaki, Sashimi\n",
      "Cats' eye\n",
      "Kazahana Japanese Restaurant\n",
      "Brook's Cafe\n",
      "Sakuragi Omakase\n",
      "Kazahana Japanese Restaurant\n",
      "Yummy Sushi\n",
      "Ichitora\n",
      "Wakayama Japanese Restaurant\n",
      "Cats' eye\n",
      "Chao Chao Gyoza\n",
      "Chao Chao Gyoza\n",
      "Sushi Jun\n",
      "Akita Crab Shabu Shabu Specialist\n",
      "Sushi Jun\n",
      "Gin Sai Japanese Restaurant\n",
      "Isoya Japanese Vegetarian Restaurant\n",
      "Koku Ryu Ramen\n",
      "Woo Tung Yakiniku Dining Bar\n",
      "Kuroganeya\n",
      "Tokyo Agura\n",
      "Koku Ryu Ramen\n",
      "Koku Ryu Ramen\n",
      "Cats' eye\n",
      "Kuroganeya\n",
      "Kanizen\n",
      "Sushi Express\n",
      "Cats' eye\n",
      "Koku Ryu Ramen\n",
      "Kamitora Ramen\n",
      "Koku Ryu Ramen\n",
      "Cats' eye\n",
      "hana-musubi\n",
      "Ronin Japanese Cuisine\n",
      "Bekan Teppanyaki Japanese Restaurant\n",
      "The Kitchen\n",
      "Nasubi\n",
      "Kamitora Ramen\n",
      "Kamitora Ramen\n",
      "Kamitora Ramen\n",
      "Gin Sai Japanese Restaurant\n",
      "Wakayama Japanese Restaurant\n",
      "Kanizen\n",
      "Kanizen\n",
      "ABURI\n",
      "hana-musubi\n",
      "Habitat Japanese Restaurant\n",
      "J-Dog\n",
      "S.A.E.\n",
      "Hachiban Ramen\n",
      "Kanizen\n",
      "Italian Tomato Caf Jr\n",
      "The Yuu Japanese Dining\n",
      "Yuyu Sushi\n",
      "Yukitei Ramen\n",
      "Hachiban Ramen\n",
      "Hachiban Ramen\n",
      "Yukitei Ramen\n",
      "Woo Tung Yakiniku Dining Bar\n",
      "Suzuike Japanese Cuisine\n",
      "Suzuike Japanese Cuisine\n",
      "Great Asia Japanese Restaurant\n",
      "Mayotte\n",
      "Hachiban Ramen\n",
      "The Yuu Japanese Dining\n",
      "Yukitei Ramen\n",
      "Ming General Japanese Sushi Restaurant\n",
      "Tonbe\n",
      "Tonbe\n",
      "Tonbe\n",
      "S.A.E.\n",
      "Tonbe\n",
      "Tonbe\n",
      "Masamura\n",
      "Yuyu Sushi\n",
      "Tonbe\n",
      "Morihachi Kitchen\n",
      "Great Asia Japanese Restaurant\n",
      "Akita Teppanyaki, Sashimi\n",
      "TenSho\n",
      "Itacho Sushi\n",
      "Otemachi Japanese Restaurant\n",
      "Bento Express by Jusco\n",
      "The Yuu Japanese Dining\n",
      "Great Asia Japanese Restaurant\n"
     ]
    }
   ],
   "source": [
    "URL = \"https://www.openrice.com/en/hongkong/restaurant/review/search.htm?smile=&daycategoryid=&pricetype=2&hasprice=1&district_id=1022&cuisine_id=2009&inputstrreview=\"\n",
    "driver = webdriver.Chrome()\n",
    "driver.get(URL)\n",
    "html = driver.page_source\n",
    "soup = BeautifulSoup(html, \"html.parser\")\n",
    "element = driver.find_element_by_xpath('//*[@id=\"togglefullreview\"]')\n",
    "element.click()\n",
    "time.sleep(5)\n",
    "\n",
    "with open(\"Openrice_Wanchai_Japanese_1.csv\",\"a\") as f:\n",
    "    WriteFile = csv.writer(f)\n",
    "    WriteFile.writerow([\"District\",\"Cuisine\",\"Reviews\",\"Restaurant_Name\",\"Rating\",\"Cost\",\"Wait_Time\",\"Restuaruant_Link\"])\n",
    "\n",
    "district = \"Wan Chai\"\n",
    "cuisine = \"Japanese\"\n",
    "\n",
    "nolu=2\n",
    "numberofloopspages = 1\n",
    "while numberofloopspages<11:\n",
    "    \n",
    "    time.sleep(5)\n",
    "\n",
    "    for i in soup.find_all(\"div\", class_ = \"sr2_review_bk rel_pos\"):  \n",
    "        \n",
    "# review\n",
    "        try:\n",
    "            review_dirty = i.find(class_ = \"sr2_review_body div_br_word MB5\").get_text().strip().replace('\\n','').encode('ASCII', 'ignore')\n",
    "            review = review_dirty.decode(\"utf-8\")\n",
    "        except:\n",
    "            review = np.nan\n",
    "\n",
    "# restaurant name\n",
    "        try:\n",
    "            restaurant_name_dirty = i.find(\"a\", class_ = \"hiddenlink\").get_text().encode('ASCII', 'ignore')\n",
    "            restaurant_name = restaurant_name_dirty.decode(\"utf-8\")\n",
    "            print(restaurant_name)\n",
    "        except:\n",
    "            restaurant_name = np.nan\n",
    "\n",
    "# Rating\n",
    "        try:\n",
    "            rating_dirty = i.find(\"meta\", itemprop=\"ratingvalue\")\n",
    "            rating = re.findall(r\"\\d+\\.\\d+\", str(rating_dirty))[0]\n",
    "        except:\n",
    "            rating = np.nan\n",
    "\n",
    "# Cost  \n",
    "        try:\n",
    "            details = i.find_all(class_= \"FR PT10 PB10\")\n",
    "            cost = re.findall(r\"\\$(\\d+)\", str(details))[0]\n",
    "        except:\n",
    "            cost = np.nan\n",
    "\n",
    "# Wait time            \n",
    "        try:\n",
    "            details = i.find_all(class_= \"FR PT10 PB10\")\n",
    "            wait_time = re.findall(r'(\\d+?) min',str(details))[0]\n",
    "        except:\n",
    "            wait_time = np.nan\n",
    "            \n",
    "# restaurant link\n",
    "        try:\n",
    "            rest_link_dirty = i.find(class_ = \"hiddenlink\")\n",
    "            rest_link_clean = rest_link_dirty.get(\"href\")\n",
    "            rest_link = f\"www.openrice.com{rest_link_clean}\"\n",
    "        except:\n",
    "            rest_link = np.nan\n",
    "\n",
    "        \n",
    "        with open(\"Openrice_Wanchai_Japanese_1.csv\",\"a\") as f:\n",
    "            WriteFile = csv.writer(f)    \n",
    "            WriteFile.writerow([district, cuisine, review, restaurant_name, rating, cost, wait_time, rest_link]) \n",
    "            \n",
    "#     a = nolu + 1\n",
    "    a = nolu\n",
    "    numberofloopspagesxpath = '//*[@id=\"pagingContainer\"]/div/div['+str(a)+']/a'\n",
    "    \n",
    "    try:\n",
    "        driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "        nextpage = WebDriverWait(driver, 40).until(EC.visibility_of_element_located((By.XPATH, numberofloopspagesxpath)))\n",
    "#         print(nextpage)\n",
    "        nextpage.click()\n",
    "        time.sleep(5)\n",
    "        \n",
    "        driver.get(driver.current_url)\n",
    "        soup = BeautifulSoup(driver.page_source, \"html.parser\")\n",
    "        \n",
    "        numberofloopspages+=1 \n",
    "        nolu+=2 \n",
    "        if nolu>4:\n",
    "            nolu = 4\n",
    "\n",
    "    except TimeoutException:\n",
    "        print (\"Loading took too much time\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.Wan Chai: Chinese"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fu Chuan Xiangge\n",
      "MiMiDi\n",
      "Xiao Yu Hotpot Restaurant\n",
      "Mon Kee Cafe\n",
      "Zither Garden\n",
      "Liu Yi Shou Chong Qing Hot Pot\n",
      "Wan Chai Cafe\n",
      "Mei Garden\n",
      "Madame Ching\n",
      "Shi Wei\n",
      "Hong Kong Stand\n",
      "\n",
      "Cafe Hunan\n",
      "Liu Yuan Pavilion\n",
      "Tai Wing Wah Village Cuisine\n",
      "One Harbour Road\n",
      "Loyal Dining\n",
      "Amazing May's Noodle\n",
      "Shi Wei\n",
      "\n",
      "Co-Winner Restaurant\n",
      "Nam Kee Spring Roll Noodle Co. Ltd\n",
      "Ming Kee Jumbo Seafood Restaurant\n",
      "Shi Wei\n",
      "Sportful Garden Restaurant\n",
      "Fu Sing Shark Fin Seafood Restaurant\n",
      "Madame Ching\n",
      "Wing Wah Noodle Shop\n",
      "\n",
      "1963 \n",
      "Wing Hing Restaurant\n",
      "Gem Restaurant\n",
      "Mei Garden\n",
      "Kowloon Restaurant\n",
      "Nom Nom Dumpling\n",
      "Burn & Fight\n",
      "\n",
      "\n",
      "My Cup Of Tea\n",
      "Living Road Restaurant\n",
      "Sing Kee Restaurant\n",
      "Fu Sing Shark Fin Seafood Restaurant\n",
      "\n",
      "Canton Room\n",
      "Zither Garden\n",
      "Kam's Roast Goose\n",
      "Sing Kee Restaurant\n",
      "Kee Wah Tearoom\n",
      "Joy Hing Roasted Meat\n",
      "Kam's Roast Goose\n",
      "Kam's Roast Goose\n",
      "Joy Hing Roasted Meat\n",
      "Islamic Centre Canteen\n",
      "Yu Chu Jian Bing\n",
      "Hong Zhou Restaurant\n",
      "Yixin Restaurant\n",
      "LoYe DimSum\n",
      "Islamic Centre Canteen\n",
      "\n",
      "Heart to Heart\n",
      "Cuisine Royale\n",
      "Hong Kong Lao Shang Hai Restaurant\n",
      "LoYe DimSum\n",
      "\n",
      "Fresh Juice\n",
      "Kam's Roast Goose\n",
      "CEO Neway\n",
      "Shuang Xi Lou\n",
      "LoYe DimSum\n",
      "Mon Kee Cafe\n",
      "Chiu Hing Fishball Rice Noodle\n",
      "Shanghai Lao Lao\n",
      "Taste Restaurant & Bar\n",
      "Car Noodle's Family\n",
      "Capital Caf\n",
      "Taste Restaurant & Bar\n",
      "Kam Fung Restaurant\n",
      "Sun King Yuen Curry Restaurant\n",
      "LoYe DimSum\n",
      "Cuisine Royale\n",
      "Yu Chuan Club\n",
      "Tsui Wah Restaurant\n",
      "Hay!\n",
      "Hong Zhou Restaurant\n",
      "1963 \n",
      "Trusty Congee King\n",
      "Dumpling Pro\n",
      "1963 \n",
      "1963 \n",
      "Hay!\n",
      "Tang's Cuisine\n",
      "Car Noodle's Family\n",
      "Xi Zhan\n",
      "Tang's Cuisine\n",
      "Barchua House\n",
      "Canton Room\n",
      "Che's Cantonese Restaurant\n",
      "Heart to Heart\n",
      "Under Bridge Spicy Crab\n",
      "Kam Kee Cafe\n",
      "3.6.9. Restaurant Shanghai Food\n",
      "Kam's Roast Goose\n",
      "TamJai SamGor\n",
      "\n",
      "Olala\n",
      "Hokkaido Dairy Farm Milk Restaurant\n",
      "Joy Hing Roasted Meat\n",
      "Empire City Chinese Cuisine\n",
      "Fook Lam Moon\n",
      "Peking Shui Jiao Wong\n",
      "\n",
      "Cafe Hunan\n",
      "Gem Restaurant\n",
      "Maureen\n",
      "Qi House of Sichuan\n",
      "Joy Hing Roasted Meat\n",
      "Kuen Kee Won Ton Noodle\n",
      "ZAAN\n",
      "Gorden Rice\n",
      "Chiu Hing Fishball Rice Noodle\n",
      "Fook Chun Bo Restaurant\n",
      "Che's Cantonese Restaurant\n",
      "Tung Fong Siu Kee Yuen\n",
      "Fu Sing Shark Fin Seafood Restaurant\n",
      "3.6.9. Restaurant Shanghai Food\n",
      "Sichuan Paradise\n",
      "Mr. Bing\n",
      "Kin's Kitchen\n",
      "\n",
      "Capital Caf\n",
      "Kin's Kitchen\n",
      "Seventh Son Restaurant\n",
      "Sun King Yuen Curry Restaurant\n",
      "Maureen\n",
      "Fook Lam Moon\n",
      "Daimenko\n",
      "Kam Fung Restaurant\n",
      "ZAAN\n",
      "The Grand Hall\n",
      "May Wong Fish Ball Noodle\n",
      "Barchua House\n",
      "American Restaurant\n",
      "Keung Kee\n",
      "Dynasty Restaurant\n",
      "Trusty Congee King\n",
      "Sun King Yuen Curry Restaurant\n",
      "Wing's Catering\n",
      "Daimenko\n",
      "Golden Bauhinia Cantonese Restaurant\n",
      "Lee House Restaurant\n",
      "Maureen\n",
      "Tsui Wah Restaurant\n",
      "Trusty Congee King\n",
      "Olala\n",
      "Maureen\n",
      "\n",
      "Yuet Heung Restaurant\n",
      "Peking Shui Jiao Wong\n",
      "Harbour Kitchen\n",
      "Sun Kau Kee Noodle Shop\n",
      "Ming Garden Restaurant\n",
      "Wing's Catering\n",
      "Fook Lam Moon\n",
      "Trusty Gourmet\n",
      "Hong Zhou Restaurant\n",
      "Golden Bauhinia Cantonese Restaurant\n",
      "\n",
      "One Harbour Road\n",
      "American Restaurant\n",
      "Under Bridge Spicy Crab\n",
      "Lee House Restaurant\n",
      "Shun King Restaurant\n",
      "Joy Hing Roasted Meat\n",
      "Capital Caf\n",
      "Trusty Gourmet\n",
      "Congress Restaurant\n",
      "Fook Lam Moon\n",
      "Joy Hing Roasted Meat\n",
      "Dumpling Pro\n",
      "Yin Yang\n",
      "Sun King Yuen Curry Restaurant\n",
      "\n",
      "\n",
      "Your Restaurant\n",
      "Big Wife Noodle\n",
      "Fairwood\n",
      "Hay Hay Kitchen\n",
      "Sun King Yuen Curry Restaurant\n",
      "Crystal Jade La Mian Xiao Long Bao\n",
      "Kam Fung Restaurant\n",
      "\n",
      "Happy Veggies\n",
      "\n",
      "Capital Caf\n",
      "Lan Fong Cafe\n",
      "Ming Garden Restaurant\n",
      "Fu Tung Gongdong Restaurant\n",
      "Fook Lam Moon\n",
      "8 Happiness\n",
      "Lan Fong Cafe\n",
      "3.6.9. Restaurant Shanghai Food\n",
      "Capital Caf\n",
      "Congress Restaurant\n",
      "Tsuen Kee\n",
      "American Restaurant\n",
      "Ho Hah Restaurant\n",
      "Fook Lam Moon\n",
      "Capital Caf\n",
      "Joy Hing Roasted Meat\n",
      "Easy Drink Easy Go\n",
      "New Shanghai\n",
      "Veggie Palace\n",
      "Jardin de Jade\n",
      "Congress Restaurant\n",
      "Golden Bauhinia Cantonese Restaurant\n",
      "Che's Cantonese Restaurant\n",
      "Fat Mama's Dessert\n",
      "Car Noodle's Family\n",
      "Capital Caf\n",
      "Che's Cantonese Restaurant\n",
      "Congress Restaurant\n",
      "Chiu Yuen Chiu Chow Noodle\n",
      "Rose Kitchen\n",
      "Wing Wah Noodle Shop\n",
      "Olala\n",
      "Trusty Gourmet\n",
      "Lung Moon Restaurant\n",
      "Wing Wah Noodle Shop\n",
      "Fu Sing Shark Fin Seafood Restaurant\n",
      "Che's Cantonese Restaurant\n",
      "Fu Sing Shark Fin Seafood Restaurant\n",
      "Congress Restaurant\n",
      "\n",
      "Hong Kong Lao Shang Hai Restaurant\n",
      "Shun King Restaurant\n",
      "Dragon King Restaurant\n",
      "\n",
      "Fu Sing Shark Fin Seafood Restaurant\n",
      "Olala\n",
      "Ada \n"
     ]
    }
   ],
   "source": [
    "URL = \"https://www.openrice.com/en/hongkong/restaurant/review/search.htm?smile=&daycategoryid=&pricetype=2&hasprice=1&district_id=1022&cuisine_id=1999&inputstrreview=\"\n",
    "driver = webdriver.Chrome()\n",
    "driver.get(URL)\n",
    "html = driver.page_source\n",
    "soup = BeautifulSoup(html, \"html.parser\")\n",
    "element = driver.find_element_by_xpath('//*[@id=\"togglefullreview\"]')\n",
    "element.click()\n",
    "time.sleep(5)\n",
    "\n",
    "with open(\"Openrice_Wanchai_Chinese_1.csv\",\"a\") as f:\n",
    "    WriteFile = csv.writer(f)\n",
    "    WriteFile.writerow([\"District\",\"Cuisine\",\"Reviews\",\"Restaurant_Name\",\"Rating\",\"Cost\",\"Wait_Time\",\"Restuaruant_Link\"])\n",
    "\n",
    "district = \"Wan Chai\"\n",
    "cuisine = \"Chinese\"\n",
    "\n",
    "nolu=2\n",
    "numberofloopspages = 1\n",
    "while numberofloopspages<17:\n",
    "    \n",
    "    time.sleep(5)\n",
    "\n",
    "    for i in soup.find_all(\"div\", class_ = \"sr2_review_bk rel_pos\"):  \n",
    "        \n",
    "# review\n",
    "        try:\n",
    "            review_dirty = i.find(class_ = \"sr2_review_body div_br_word MB5\").get_text().strip().replace('\\n','').encode('ASCII', 'ignore')\n",
    "            review = review_dirty.decode(\"utf-8\")\n",
    "        except:\n",
    "            review = np.nan\n",
    "\n",
    "# restaurant name\n",
    "        try:\n",
    "            restaurant_name_dirty = i.find(\"a\", class_ = \"hiddenlink\").get_text().encode('ASCII', 'ignore')\n",
    "            restaurant_name = restaurant_name_dirty.decode(\"utf-8\")\n",
    "            print(restaurant_name)\n",
    "        except:\n",
    "            restaurant_name = np.nan\n",
    "\n",
    "# Rating\n",
    "        try:\n",
    "            rating_dirty = i.find(\"meta\", itemprop=\"ratingvalue\")\n",
    "            rating = re.findall(r\"\\d+\\.\\d+\", str(rating_dirty))[0]\n",
    "        except:\n",
    "            rating = np.nan\n",
    "\n",
    "# Cost  \n",
    "        try:\n",
    "            details = i.find_all(class_= \"FR PT10 PB10\")\n",
    "            cost = re.findall(r\"\\$(\\d+)\", str(details))[0]\n",
    "        except:\n",
    "            cost = np.nan\n",
    "\n",
    "# Wait time            \n",
    "        try:\n",
    "            details = i.find_all(class_= \"FR PT10 PB10\")\n",
    "            wait_time = re.findall(r'(\\d+?) min',str(details))[0]\n",
    "        except:\n",
    "            wait_time = np.nan\n",
    "            \n",
    "# restaurant link\n",
    "        try:\n",
    "            rest_link_dirty = i.find(class_ = \"hiddenlink\")\n",
    "            rest_link_clean = rest_link_dirty.get(\"href\")\n",
    "            rest_link = f\"www.openrice.com{rest_link_clean}\"\n",
    "        except:\n",
    "            rest_link = np.nan\n",
    "        \n",
    "        with open(\"Openrice_Wanchai_Chinese_1.csv\",\"a\") as f:\n",
    "            WriteFile = csv.writer(f)    \n",
    "            WriteFile.writerow([district, cuisine, review, restaurant_name, rating, cost, wait_time, rest_link]) \n",
    "\n",
    "    a = nolu\n",
    "    numberofloopspagesxpath = '//*[@id=\"pagingContainer\"]/div/div['+str(a)+']/a'\n",
    "    \n",
    "    try:\n",
    "        driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "        nextpage = WebDriverWait(driver, 40).until(EC.visibility_of_element_located((By.XPATH, numberofloopspagesxpath)))\n",
    "#         print(nextpage)\n",
    "        nextpage.click()\n",
    "        time.sleep(5)\n",
    "        \n",
    "        driver.get(driver.current_url)\n",
    "        soup = BeautifulSoup(driver.page_source, \"html.parser\")\n",
    "        \n",
    "        numberofloopspages+=1 \n",
    "        nolu+=2 \n",
    "        if nolu>4:\n",
    "            nolu = 4\n",
    "\n",
    "    except TimeoutException:\n",
    "        print (\"Loading took too much time\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Wan Chai: Thai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sun Thai Restaurant\n",
      "Samsen\n",
      "Samsen\n",
      "Koon Thai Hai Nam Chicken\n",
      "Tamarind Pan-Asian Restaurant & Bar\n",
      "RA CHA MOO YANG\n",
      "Samsen\n",
      "Sun Thai Restaurant\n",
      "Sawali Club\n",
      "Samsen\n",
      "Tamarind Pan-Asian Restaurant & Bar\n",
      "Chili Club\n",
      "Sawali Club\n",
      "Samsen\n",
      "Thai Hut\n",
      "Thai Flavour\n",
      "Samsen\n",
      "Samsen\n",
      "MAZ Thai & BBQ\n",
      "Papillon Caffe\n",
      "Samsen\n",
      "Thai On Nine By Kea\n",
      "MAZ Thai & BBQ\n",
      "Koh Thai\n",
      "Koh Thai\n",
      "Koh Thai\n",
      "New Bangkok Restaurant\n",
      "Papillon Caffe\n",
      "Papillon Caffe\n",
      "Sawadika\n",
      "Koon Thai Hai Nam Chicken\n",
      "Papillon Caffe\n",
      "Thai Farmer Restaurant\n",
      "The Spice House Restaurant\n",
      "Koh Thai\n",
      "Chai Yo Thai\n",
      "Trendy Taste\n",
      "Thai\n",
      "Thai Delight\n",
      "Thai Flavour\n",
      "Chili Club\n",
      "RA CHA MOO YANG\n",
      "Thai Dynasty Restaurant\n"
     ]
    }
   ],
   "source": [
    "URL = \"https://www.openrice.com/en/hongkong/restaurant/review/search.htm?smile=&daycategoryid=&pricetype=2&hasprice=1&district_id=1022&cuisine_id=2004&inputstrreview=\"\n",
    "driver = webdriver.Chrome()\n",
    "driver.get(URL)\n",
    "html = driver.page_source\n",
    "soup = BeautifulSoup(html, \"html.parser\")\n",
    "element = driver.find_element_by_xpath('//*[@id=\"togglefullreview\"]')\n",
    "element.click()\n",
    "time.sleep(5)\n",
    "\n",
    "with open(\"Openrice_Wanchai_Thai_1.csv\",\"a\") as f:\n",
    "    WriteFile = csv.writer(f)\n",
    "    WriteFile.writerow([\"District\",\"Cuisine\",\"Reviews\",\"Restaurant_Name\",\"Rating\",\"Cost\",\"Wait_Time\",\"Restuaruant_Link\"])\n",
    "\n",
    "district = \"Wan Chai\"\n",
    "cuisine = \"Thai\"\n",
    "\n",
    "nolu=2\n",
    "numberofloopspages = 1\n",
    "while numberofloopspages<4:\n",
    "\n",
    "    time.sleep(5)\n",
    "\n",
    "    for i in soup.find_all(\"div\", class_ = \"sr2_review_bk rel_pos\"):  \n",
    "        \n",
    "# review\n",
    "        try:\n",
    "            review_dirty = i.find(class_ = \"sr2_review_body div_br_word MB5\").get_text().strip().replace('\\n','').encode('ASCII', 'ignore')\n",
    "            review = review_dirty.decode(\"utf-8\")\n",
    "        except:\n",
    "            review = np.nan\n",
    "\n",
    "# restaurant name\n",
    "        try:\n",
    "            restaurant_name_dirty = i.find(\"a\", class_ = \"hiddenlink\").get_text().encode('ASCII', 'ignore')\n",
    "            restaurant_name = restaurant_name_dirty.decode(\"utf-8\")\n",
    "            print(restaurant_name)\n",
    "        except:\n",
    "            restaurant_name = np.nan\n",
    "\n",
    "# Rating\n",
    "        try:\n",
    "            rating_dirty = i.find(\"meta\", itemprop=\"ratingvalue\")\n",
    "            rating = re.findall(r\"\\d+\\.\\d+\", str(rating_dirty))[0]\n",
    "        except:\n",
    "            rating = np.nan\n",
    "\n",
    "# Cost  \n",
    "        try:\n",
    "            details = i.find_all(class_= \"FR PT10 PB10\")\n",
    "            cost = re.findall(r\"\\$(\\d+)\", str(details))[0]\n",
    "        except:\n",
    "            cost = np.nan\n",
    "\n",
    "# Wait time            \n",
    "        try:\n",
    "            details = i.find_all(class_= \"FR PT10 PB10\")\n",
    "            wait_time = re.findall(r'(\\d+?) min',str(details))[0]\n",
    "        except:\n",
    "            wait_time = np.nan\n",
    "            \n",
    "# restaurant link\n",
    "        try:\n",
    "            rest_link_dirty = i.find(class_ = \"hiddenlink\")\n",
    "            rest_link_clean = rest_link_dirty.get(\"href\")\n",
    "            rest_link = f\"www.openrice.com{rest_link_clean}\"\n",
    "        except:\n",
    "            rest_link = np.nan\n",
    "        \n",
    "        \n",
    "        with open(\"Openrice_Wanchai_Thai_1.csv\",\"a\") as f:\n",
    "            WriteFile = csv.writer(f)    \n",
    "            WriteFile.writerow([district, cuisine, review, restaurant_name, rating, cost, wait_time, rest_link]) \n",
    "            \n",
    "    a = nolu\n",
    "    numberofloopspagesxpath = '//*[@id=\"pagingContainer\"]/div/div['+str(a)+']/a'\n",
    "    \n",
    "    try:\n",
    "        driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "        nextpage = WebDriverWait(driver, 40).until(EC.visibility_of_element_located((By.XPATH, numberofloopspagesxpath)))\n",
    "#         print(nextpage)\n",
    "        nextpage.click()\n",
    "        time.sleep(5)\n",
    "        \n",
    "        driver.get(driver.current_url)\n",
    "        soup = BeautifulSoup(driver.page_source, \"html.parser\")\n",
    "        \n",
    "        numberofloopspages+=1 \n",
    "        nolu+=2 \n",
    "        if nolu>4:\n",
    "            nolu = 4\n",
    "\n",
    "    except TimeoutException:\n",
    "        print (\"Loading took too much time\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Admiralty: Italian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Motorino\n",
      "Gi Trattoria Italiana\n",
      "Pici\n",
      "Fini's\n",
      "Pirata\n",
      "Pizza Hut\n",
      "Pici\n",
      "Motorino\n",
      "Assaggio Trattoria Italiana\n",
      "Pici\n",
      "Pirata\n",
      "Fini's\n",
      "Osteria Marzia\n",
      "Pici\n",
      "Pici\n",
      "Joe Bananas\n",
      "L16\n",
      "Pirata\n",
      "Osteria Marzia\n",
      "Pici\n",
      "Motorino\n",
      "Cheeky Pasta\n",
      "Pirata\n",
      "Paisano's Pizzeria\n",
      "Fishsteria\n",
      "Grill 28\n",
      "La Cucina Italiana\n",
      "Pirata\n",
      "Assaggio Trattoria Italiana\n",
      "Palco Ristorante\n",
      "Al Dente\n",
      "Grappas QRE\n",
      "Palco Ristorante\n",
      "Pici\n",
      "Pirata\n",
      "Divino Patio Ristorante Bar Pizzeria\n",
      "Avanti Pizzeria\n",
      "Pirata\n",
      "Pirata\n",
      "Gi Trattoria Italiana\n",
      "Pirata\n",
      "Jigger Pitcher\n",
      "Pici\n",
      "Pici\n",
      "Paisano's Pizzeria\n",
      "Jigger Pitcher\n",
      "Giando Italian Restaurant & Bar\n",
      "Paisano's Pizzeria\n",
      "Assaggio Trattoria Italiana\n",
      "Motorino\n",
      "Blue Place Cafe\n",
      "Grissini \n",
      "Fishsteria\n",
      "Pirata\n",
      "da Via\n",
      "da Via\n",
      "da Via\n",
      "da Via\n",
      "Pizza Hut\n",
      "Empress Cafe\n",
      "Pizza Hut\n",
      "Le Blanc\n",
      "Pausa\n",
      "Empress Cafe\n",
      "Empress Cafe\n",
      "Pausa\n",
      "Pausa\n",
      "Paisano's Pizzeria\n",
      "Pausa\n",
      "HABIT caff \n",
      "Opera House Italian Restaurant & Bistrot\n",
      "Ramas Oyster Bar & Grill\n",
      "Pausa\n",
      "Felicita 1929\n",
      "Felicita 1929\n",
      "Pausa\n",
      "PizzaExpress\n",
      "Opera House Italian Restaurant & Bistrot\n",
      "Grissini \n",
      "Opera House Italian Restaurant & Bistrot\n",
      "Empress Cafe\n",
      "Assaggio Trattoria Italiana\n",
      "Assaggio Trattoria Italiana\n",
      "Felicita 1929\n",
      "Opera House Italian Restaurant & Bistrot\n",
      "Papi\n",
      "Davinc! Steak & Bar\n",
      "Paisano's Pizzeria\n",
      "Antipasto\n",
      "Paisano's Pizzeria\n",
      "Giando Italian Restaurant & Bar\n",
      "Giando Italian Restaurant & Bar\n",
      "Ciacoe\n",
      "Davinc! Steak & Bar\n",
      "Antipasto\n",
      "Giando Italian Restaurant & Bar\n",
      "Big Pizza\n",
      "Divino Patio Ristorante Bar Pizzeria\n",
      "La Cucina Italiana\n",
      "Zummer\n",
      "Angus\n",
      "Antipasto\n",
      "Zummer\n",
      "PizzaExpress\n",
      "Zummer\n",
      "PizzaExpress\n",
      "Assaggio Trattoria Italiana\n",
      "Al Dente\n",
      "Al Dente\n",
      "Caffe Kenon & Bistro\n",
      "Assaggio Trattoria Italiana\n",
      "Assaggio Trattoria Italiana\n",
      "Assaggio Trattoria Italiana\n",
      "Assaggio Trattoria Italiana\n",
      "Assaggio Trattoria Italiana\n",
      "caff HABIT\n",
      "Caffe Kenon & Bistro\n",
      "Pepino Italian Restaurant\n",
      "Antipasto\n",
      "PizzaExpress\n",
      "Antipasto\n",
      "La Bons Brasserie\n",
      "PizzaExpress\n",
      "La Cucina Italiana\n",
      "Magia Italian Gourmet\n",
      "La Baita Italian Restaurant & Bar\n",
      "caff HABIT\n",
      "La Piazzetta\n",
      "La Baita Italian Restaurant & Bar\n",
      "La Cucina Italiana\n",
      "Spuntini\n",
      "Caffe Pascucci\n",
      "il Bel Paese\n",
      "La Bons Brasserie\n",
      "PizzaExpress\n",
      "Stefanos Homemade Italian American Cuisine\n",
      "La Cucina Italiana\n",
      "Al Dente\n",
      "Spuntini\n",
      "Amici\n",
      "Grissini \n",
      "Pizzetteria\n",
      "Al Dente Past Grill & Seafood\n",
      "Al Dente\n",
      "Spuntini\n",
      "Spuntini\n",
      "Al Dente\n",
      "Al Dente\n",
      "Al Dente Past Grill & Seafood\n",
      "La Bons Cafe\n"
     ]
    }
   ],
   "source": [
    "URL = \"https://www.openrice.com/en/hongkong/restaurant/review/search.htm?smile=&daycategoryid=&pricetype=2&hasprice=1&district_id=1022&cuisine_id=3006&inputstrreview=\"\n",
    "driver = webdriver.Chrome()\n",
    "driver.get(URL)\n",
    "html = driver.page_source\n",
    "soup = BeautifulSoup(html, \"html.parser\")\n",
    "element = driver.find_element_by_xpath('//*[@id=\"togglefullreview\"]')\n",
    "element.click()\n",
    "time.sleep(5)\n",
    "\n",
    "with open(\"Openrice_Wanchai_Italian_1.csv\",\"a\") as f:\n",
    "    WriteFile = csv.writer(f)\n",
    "    WriteFile.writerow([\"District\",\"Cuisine\",\"Reviews\",\"Restaurant_Name\",\"Rating\",\"Cost\",\"Wait_Time\",\"Restuaruant_Link\"])\n",
    "\n",
    "district = \"Wan Chai\"\n",
    "cuisine = \"Italian\"\n",
    "\n",
    "nolu=2\n",
    "numberofloopspages = 1\n",
    "while numberofloopspages<11:\n",
    "    \n",
    "    time.sleep(5)\n",
    "    for i in soup.find_all(\"div\", class_ = \"sr2_review_bk rel_pos\"):  \n",
    "        \n",
    "# review\n",
    "        try:\n",
    "            review_dirty = i.find(class_ = \"sr2_review_body div_br_word MB5\").get_text().strip().replace('\\n','').encode('ASCII', 'ignore')\n",
    "            review = review_dirty.decode(\"utf-8\")\n",
    "        except:\n",
    "            review = np.nan\n",
    "\n",
    "# restaurant name\n",
    "        try:\n",
    "            restaurant_name_dirty = i.find(\"a\", class_ = \"hiddenlink\").get_text().encode('ASCII', 'ignore')\n",
    "            restaurant_name = restaurant_name_dirty.decode(\"utf-8\")\n",
    "            print(restaurant_name)\n",
    "        except:\n",
    "            restaurant_name = np.nan\n",
    "\n",
    "# Rating\n",
    "        try:\n",
    "            rating_dirty = i.find(\"meta\", itemprop=\"ratingvalue\")\n",
    "            rating = re.findall(r\"\\d+\\.\\d+\", str(rating_dirty))[0]\n",
    "        except:\n",
    "            rating = np.nan\n",
    "\n",
    "# Cost  \n",
    "        try:\n",
    "            details = i.find_all(class_= \"FR PT10 PB10\")\n",
    "            cost = re.findall(r\"\\$(\\d+)\", str(details))[0]\n",
    "        except:\n",
    "            cost = np.nan\n",
    "\n",
    "# Wait time            \n",
    "        try:\n",
    "            details = i.find_all(class_= \"FR PT10 PB10\")\n",
    "            wait_time = re.findall(r'(\\d+?) min',str(details))[0]\n",
    "        except:\n",
    "            wait_time = np.nan\n",
    "            \n",
    "# restaurant link\n",
    "        try:\n",
    "            rest_link_dirty = i.find(class_ = \"hiddenlink\")\n",
    "            rest_link_clean = rest_link_dirty.get(\"href\")\n",
    "            rest_link = f\"www.openrice.com{rest_link_clean}\"\n",
    "        except:\n",
    "            rest_link = np.nan\n",
    "        \n",
    "        with open(\"Openrice_Wanchai_Italian_1.csv\",\"a\") as f:\n",
    "            WriteFile = csv.writer(f)    \n",
    "            WriteFile.writerow([district, cuisine, review, restaurant_name, rating, cost, wait_time, rest_link]) \n",
    "            \n",
    "    a = nolu\n",
    "    numberofloopspagesxpath = '//*[@id=\"pagingContainer\"]/div/div['+str(a)+']/a'\n",
    "    \n",
    "    try:\n",
    "        driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "        nextpage = WebDriverWait(driver, 40).until(EC.visibility_of_element_located((By.XPATH, numberofloopspagesxpath)))\n",
    "        nextpage.click()\n",
    "        time.sleep(5)\n",
    "        \n",
    "        driver.get(driver.current_url)\n",
    "        soup = BeautifulSoup(driver.page_source, \"html.parser\")\n",
    "#         element = driver.find_element_by_xpath('//*[@id=\"togglefullreview\"]')\n",
    "#         element.click()\n",
    "#         time.sleep(10)\n",
    "        \n",
    "        numberofloopspages+=1 \n",
    "        nolu+=2 \n",
    "        if nolu>4:\n",
    "            nolu = 4\n",
    "\n",
    "    except TimeoutException:\n",
    "        print (\"Loading took too much time\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Wan Chai: American"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Morty's Delicatessen\n",
      "Honbo\n",
      "TED's Lookout\n",
      "Mr. Crab by The Captain's House\n",
      "Mr. Crab by The Captain's House\n",
      "McDonald's\n",
      "Morty's Delicatessen\n",
      "Fini's\n",
      "Mr. Crab by The Captain's House\n",
      "Five Guys\n",
      "Five Guys\n",
      "Fini's\n",
      "Five Guys\n",
      "Honbo\n",
      "Five Guys\n",
      "Five Guys\n",
      "Five Guys\n",
      "Five Guys\n",
      "Five Guys\n",
      "Joe Bananas\n",
      "Burger Home\n",
      "The Pok Co\n",
      "Burger Joys\n",
      "Morty's Delicatessen\n",
      "Cali-Mex Taqueria\n",
      "Honbo\n",
      "Grill 28\n",
      "The Butchers Club\n",
      "Morty's Delicatessen\n",
      "Burger Joys\n",
      "The Butchers Club\n",
      "Beef & Liberty\n",
      "Stone Nullah Tavern\n",
      "Beef & Liberty\n",
      "Mr. Crab by The Captain's House\n",
      "The Butchers Club\n",
      "Mr. Crab by The Captain's House\n",
      "Burger Joys\n",
      "Honbo\n",
      "Honbo\n",
      "Beef & Liberty\n",
      "Honbo\n",
      "The Butchers Club\n",
      "The Butchers Club\n",
      "Stone Nullah Tavern\n",
      "Moonshine & The Po'Boys\n",
      "Outback Steakhouse\n",
      "Burger Home\n",
      "Burger Joys\n",
      "Burger Joys\n",
      "Burger Joys\n",
      "Moonshine & The Po'Boys\n",
      "Burger Joys\n",
      "Beef & Liberty\n",
      "Stone Nullah Tavern\n",
      "Caliburger\n",
      "The Butchers Club\n",
      "Big Jo's\n",
      "Burger Joys\n",
      "The Butchers Club\n",
      "Beef & Liberty\n",
      "The Butchers Club\n",
      "The Butchers Club\n",
      "Cali-Mex Taqueria\n",
      "Big Jo's\n",
      "Beef & Liberty\n",
      "TED's Lookout\n",
      "The Butchers Club\n",
      "The Butchers Club\n",
      "The Butchers Club\n",
      "The Butchers Club\n",
      "The Butchers Club\n",
      "The Butchers Club\n",
      "The Butchers Club\n",
      "Beef & Liberty\n",
      "Dressed\n",
      "Caliburger\n",
      "Caliburger\n",
      "Beef & Liberty\n",
      "TED's Lookout\n",
      "Caliburger\n",
      "Beef & Liberty\n",
      "Outback Steakhouse\n",
      "Caliburger\n",
      "Caliburger\n",
      "Caliburger\n",
      "California Vintage\n",
      "California Vintage\n",
      "Slim's\n",
      "Burger King\n",
      "Dressed\n",
      "Burger Home\n",
      "Starbucks Coffee\n",
      "Outback Steakhouse\n",
      "Shake'em Buns\n",
      "Yogurtime\n",
      "The Big Apple\n",
      "Shake'em Buns\n",
      "Dressed\n",
      "The Big Apple\n",
      "Kentucky Fried Chicken\n",
      "Fatburger\n",
      "Fatburger\n",
      "Dressed\n",
      "McDonald's\n"
     ]
    }
   ],
   "source": [
    "URL = \"https://www.openrice.com/en/hongkong/restaurant/review/search.htm?smile=&daycategoryid=&pricetype=2&hasprice=1&district_id=1022&cuisine_id=4001&inputstrreview=\"\n",
    "driver = webdriver.Chrome()\n",
    "driver.get(URL)\n",
    "html = driver.page_source\n",
    "soup = BeautifulSoup(html, \"html.parser\")\n",
    "element = driver.find_element_by_xpath('//*[@id=\"togglefullreview\"]')\n",
    "element.click()\n",
    "time.sleep(5)\n",
    "\n",
    "with open(\"Openrice_Wanchai_American_1.csv\",\"a\") as f:\n",
    "    WriteFile = csv.writer(f)\n",
    "    WriteFile.writerow([\"District\",\"Cuisine\",\"Reviews\",\"Restaurant_Name\",\"Rating\",\"Cost\",\"Wait_Time\",\"Restuaruant_Link\"])\n",
    "\n",
    "district = \"Wan Chai\"\n",
    "cuisine = \"American\"\n",
    "\n",
    "nolu=2\n",
    "numberofloopspages = 1\n",
    "while numberofloopspages<8:\n",
    "    \n",
    "    time.sleep(5)\n",
    "\n",
    "    for i in soup.find_all(\"div\", class_ = \"sr2_review_bk rel_pos\"):  \n",
    "        \n",
    "# review\n",
    "        try:\n",
    "            review_dirty = i.find(class_ = \"sr2_review_body div_br_word MB5\").get_text().strip().replace('\\n','').encode('ASCII', 'ignore')\n",
    "            review = review_dirty.decode(\"utf-8\")\n",
    "        except:\n",
    "            review = np.nan\n",
    "\n",
    "# restaurant name\n",
    "        try:\n",
    "            restaurant_name_dirty = i.find(\"a\", class_ = \"hiddenlink\").get_text().encode('ASCII', 'ignore')\n",
    "            restaurant_name = restaurant_name_dirty.decode(\"utf-8\")\n",
    "            print(restaurant_name)\n",
    "        except:\n",
    "            restaurant_name = np.nan\n",
    "\n",
    "# Rating\n",
    "        try:\n",
    "            rating_dirty = i.find(\"meta\", itemprop=\"ratingvalue\")\n",
    "            rating = re.findall(r\"\\d+\\.\\d+\", str(rating_dirty))[0]\n",
    "        except:\n",
    "            rating = np.nan\n",
    "\n",
    "# Cost  \n",
    "        try:\n",
    "            details = i.find_all(class_= \"FR PT10 PB10\")\n",
    "            cost = re.findall(r\"\\$(\\d+)\", str(details))[0]\n",
    "        except:\n",
    "            cost = np.nan\n",
    "\n",
    "# Wait time            \n",
    "        try:\n",
    "            details = i.find_all(class_= \"FR PT10 PB10\")\n",
    "            wait_time = re.findall(r'(\\d+?) min',str(details))[0]\n",
    "        except:\n",
    "            wait_time = np.nan\n",
    "            \n",
    "# restaurant link\n",
    "        try:\n",
    "            rest_link_dirty = i.find(class_ = \"hiddenlink\")\n",
    "            rest_link_clean = rest_link_dirty.get(\"href\")\n",
    "            rest_link = f\"www.openrice.com{rest_link_clean}\"\n",
    "        except:\n",
    "            rest_link = np.nan\n",
    "        \n",
    "        \n",
    "        with open(\"Openrice_Wanchai_American_1.csv\",\"a\") as f:\n",
    "            WriteFile = csv.writer(f)    \n",
    "            WriteFile.writerow([district, cuisine, review, restaurant_name, rating, cost, wait_time, rest_link]) \n",
    "            \n",
    "    a = nolu\n",
    "    numberofloopspagesxpath = '//*[@id=\"pagingContainer\"]/div/div['+str(a)+']/a'\n",
    "    \n",
    "    try:\n",
    "        driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "        nextpage = WebDriverWait(driver, 40).until(EC.visibility_of_element_located((By.XPATH, numberofloopspagesxpath)))\n",
    "#         print(nextpage)\n",
    "        nextpage.click()\n",
    "        time.sleep(5)\n",
    "        \n",
    "        driver.get(driver.current_url)\n",
    "        soup = BeautifulSoup(driver.page_source, \"html.parser\")\n",
    "\n",
    "        numberofloopspages+=1 \n",
    "        nolu+=2 \n",
    "        if nolu>4:\n",
    "            nolu = 4\n",
    "\n",
    "    except TimeoutException:\n",
    "        print (\"Loading took too much time\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
