{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /Users/makhy/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# https://becominghuman.ai/nlp-classifying-positive-and-negative-restaurant-reviews-bag-of-words-model-31e9abfd7286\n",
    "# https://www.kaggle.com/omkarsabnis/sentiment-analysis-on-the-yelp-reviews-dataset\n",
    "import pandas as pd\n",
    "pd.set_option('max_colwidth', 20)\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import re\n",
    "import nltk\n",
    "nltk.download(\"stopwords\")\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"Openrice_all_lunch.csv\", \n",
    "                index_col = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select only Rated Reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "District              0\n",
       "Cuisine               0\n",
       "Reviews               0\n",
       "Restaurant_Name      58\n",
       "Rating              634\n",
       "Cost                  0\n",
       "Wait_Time           602\n",
       "Restuaruant_Link      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Among the 2600+ reviews, 634 are without a rating\n",
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retain only rated reviews\n",
    "df_c = df.dropna(subset = [\"Rating\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_c.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_c.reset_index(drop=True, inplace=True)\n",
    "# df_c.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/makhy/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "# df[[\"a\", \"b\"]] = df[[\"a\", \"b\"]].apply(pd.to_numeric)\n",
    "df_c[\"Rating\"] = df_c[\"Rating\"].apply(pd.to_numeric)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classify Ratings into Positive/Nagative Sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_Good_Bad(r):\n",
    "    if r >= 3:\n",
    "        return(\"Good\")\n",
    "    else:\n",
    "        return(\"Bad\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_gnb = lambda x: transform_Good_Bad(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/makhy/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "df_c[\"Sentiment\"] = df_c[\"Rating\"].apply(add_gnb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/makhy/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "df_c[\"Sentiment_Code\"] = df_c[\"Sentiment\"].astype(\"category\").cat.codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>District</th>\n",
       "      <th>Cuisine</th>\n",
       "      <th>Reviews</th>\n",
       "      <th>Restaurant_Name</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Cost</th>\n",
       "      <th>Wait_Time</th>\n",
       "      <th>Restuaruant_Link</th>\n",
       "      <th>Grade</th>\n",
       "      <th>Grade_Code</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Sentiment_Code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Admiralty</td>\n",
       "      <td>American</td>\n",
       "      <td>I am a burger lover.Today,...</td>\n",
       "      <td>Shake Shack</td>\n",
       "      <td>4.8</td>\n",
       "      <td>140</td>\n",
       "      <td>0.0</td>\n",
       "      <td>www.openrice.com/en/hongko...</td>\n",
       "      <td>Excellent</td>\n",
       "      <td>0</td>\n",
       "      <td>Good</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Admiralty</td>\n",
       "      <td>American</td>\n",
       "      <td>Its a very famouly burger ...</td>\n",
       "      <td>Shake Shack</td>\n",
       "      <td>4.5</td>\n",
       "      <td>100</td>\n",
       "      <td>20.0</td>\n",
       "      <td>www.openrice.com/en/hongko...</td>\n",
       "      <td>Excellent</td>\n",
       "      <td>0</td>\n",
       "      <td>Good</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Admiralty</td>\n",
       "      <td>American</td>\n",
       "      <td>Love the ambiance and comf...</td>\n",
       "      <td>Commissary</td>\n",
       "      <td>3.7</td>\n",
       "      <td>170</td>\n",
       "      <td>0.0</td>\n",
       "      <td>www.openrice.com/en/hongko...</td>\n",
       "      <td>Good</td>\n",
       "      <td>1</td>\n",
       "      <td>Good</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Admiralty</td>\n",
       "      <td>American</td>\n",
       "      <td>I'm an old fashioned perso...</td>\n",
       "      <td>Ruth's Chris Steak House</td>\n",
       "      <td>3.8</td>\n",
       "      <td>350</td>\n",
       "      <td>NaN</td>\n",
       "      <td>www.openrice.com/en/hongko...</td>\n",
       "      <td>Good</td>\n",
       "      <td>1</td>\n",
       "      <td>Good</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Admiralty</td>\n",
       "      <td>American</td>\n",
       "      <td>Our China colleague came, ...</td>\n",
       "      <td>Commissary</td>\n",
       "      <td>3.2</td>\n",
       "      <td>180</td>\n",
       "      <td>0.0</td>\n",
       "      <td>www.openrice.com/en/hongko...</td>\n",
       "      <td>Okay</td>\n",
       "      <td>2</td>\n",
       "      <td>Good</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    District   Cuisine                        Reviews  \\\n",
       "0  Admiralty  American  I am a burger lover.Today,...   \n",
       "1  Admiralty  American  Its a very famouly burger ...   \n",
       "2  Admiralty  American  Love the ambiance and comf...   \n",
       "3  Admiralty  American  I'm an old fashioned perso...   \n",
       "4  Admiralty  American  Our China colleague came, ...   \n",
       "\n",
       "            Restaurant_Name  Rating  Cost  Wait_Time  \\\n",
       "0               Shake Shack     4.8   140        0.0   \n",
       "1               Shake Shack     4.5   100       20.0   \n",
       "2                Commissary     3.7   170        0.0   \n",
       "3  Ruth's Chris Steak House     3.8   350        NaN   \n",
       "4                Commissary     3.2   180        0.0   \n",
       "\n",
       "                Restuaruant_Link      Grade  Grade_Code Sentiment  \\\n",
       "0  www.openrice.com/en/hongko...  Excellent           0      Good   \n",
       "1  www.openrice.com/en/hongko...  Excellent           0      Good   \n",
       "2  www.openrice.com/en/hongko...       Good           1      Good   \n",
       "3  www.openrice.com/en/hongko...       Good           1      Good   \n",
       "4  www.openrice.com/en/hongko...       Okay           2      Good   \n",
       "\n",
       "   Sentiment_Code  \n",
       "0               1  \n",
       "1               1  \n",
       "2               1  \n",
       "3               1  \n",
       "4               1  "
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_c.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract Root Words from Reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = []\n",
    "for i in range(0,1981):\n",
    "#     try:\n",
    "    review = re.sub(\"[^a-zA-z]\", \" \",\n",
    "                   df_c[\"Reviews\"][i])\n",
    "    review = review.lower()\n",
    "    review = review.split()\n",
    "    ps = PorterStemmer()\n",
    "    review = [ps.stem(word) for word in review if not word in set(stopwords.words(\"english\"))]\n",
    "    review = \" \".join(review)\n",
    "    corpus.append(review)\n",
    "#     except Exception as e:\n",
    "#         pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['burger lover today need work admiralti thu lunch pacif place find restaur avail lunch saw shop shackburg get doubl decker natur angu beef beef cook medium combin good potato chip crispi import point chees sauc amazingit special blend cheddar american chees raspberri lemonad copilot orang red special acid good',\n",
       " 'famouli burger place hk quit crowd lunch hour line order food wait prepar food min whole order wait time find seat full lucki get seat help friendli staff gener din experi cool burger super awesom littl spice make excit tast bread soft oh wanna go back eat fri must tri item good much differ place nexttim would ask gravi sauc easi find poutin hk would definit recommenc restaur love come back love burger',\n",
       " 'love ambianc comfort food cozi space got small children corner make place even better famili weekend holiday serv brunch menu banana pancak almond honey sea salt pancak moist tasti although bit burnt bottom part toast brioch ricotta blueberri preserv lemon serv cold realli fav dish overpr chilaquil tradit mexican dish serv egg avocado well cook spici doubl chees burger fri good overload melt chees tasti beef patti definit return tri dinner menu banana pancak banana pancak toast brioch toast brioch chilaquil chilaquil doubl chees burger fri doubl chees burger fri']"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 2],\n",
       "       [0, 0, 0, ..., 1, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [2, 0, 0, ..., 1, 1, 0]])"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# trasnform the vectorized review into array\n",
    "cv = CountVectorizer(max_features = 150)\n",
    "X = cv.fit_transform(corpus).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1981"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1981"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_c[\"Sentiment_Code\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 1: Multinomial NB (0.79)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "cv = CountVectorizer(max_features = 1000)\n",
    "X = cv.fit_transform(corpus).toarray()\n",
    "y = df_c[\"Sentiment_Code\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,\n",
    "                                                   test_size = 0.2,\n",
    "                                                   random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix for MNB:\n",
      "[[ 57  28]\n",
      " [ 53 259]]\n",
      "Score: 79.6\n",
      "Classification Report:               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.52      0.67      0.58        85\n",
      "           1       0.90      0.83      0.86       312\n",
      "\n",
      "    accuracy                           0.80       397\n",
      "   macro avg       0.71      0.75      0.72       397\n",
      "weighted avg       0.82      0.80      0.80       397\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, roc_auc_score, roc_curve\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "%matplotlib inline\n",
    "\n",
    "mnb = MultinomialNB()\n",
    "mnb.fit(X_train, y_train)\n",
    "predmnb = mnb.predict(X_test)\n",
    "\n",
    "print(\"Confusion Matrix for MNB:\")\n",
    "print(confusion_matrix(y_test,predmnb))\n",
    "print(\"Score:\", round(accuracy_score(y_test,predmnb)*100,2))\n",
    "print(\"Classification Report:\", classification_report(y_test,predmnb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MNB Accuracy 0.7959697732997482\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "print(\"MNB Accuracy\", metrics.accuracy_score(y_test, predmnb))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 2: Random Forest (0.77)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix for Random Forest Classifier\n",
      "[[ 25  60]\n",
      " [ 32 280]]\n",
      "Score 76.83\n",
      "Classification Report               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.44      0.29      0.35        85\n",
      "           1       0.82      0.90      0.86       312\n",
      "\n",
      "    accuracy                           0.77       397\n",
      "   macro avg       0.63      0.60      0.61       397\n",
      "weighted avg       0.74      0.77      0.75       397\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/makhy/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rmfr = RandomForestClassifier()\n",
    "rmfr.fit(X_train, y_train)\n",
    "predrmfr = rmfr.predict(X_test)\n",
    "print(\"Confusion Matrix for Random Forest Classifier\")\n",
    "print(confusion_matrix(y_test,predrmfr))\n",
    "print(\"Score\", round(accuracy_score(y_test,predrmfr)*100,2))\n",
    "print(\"Classification Report\", \n",
    "      classification_report(y_test, predrmfr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Random Forest Accuracy\", metrics.accuracy_score(y_test, predrmfr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 3: Gradient Boosting (0.83) ** Best!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "gbe = GradientBoostingClassifier(random_state = 0)\n",
    "parameters = {\n",
    "    \"learning_rate\": [0.2, 0.4],\n",
    "#     \"max_features\": [0.5,1],\n",
    "    \"max_depth\": [3,5]\n",
    "}\n",
    "gridsearch = GridSearchCV(gbe, parameters,\n",
    "                         cv = 5,\n",
    "                         scoring = \"roc_auc\")\n",
    "gridsearch.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'learning_rate': 0.2, 'max_depth': 3}\n",
      "0.8419444905843219\n"
     ]
    }
   ],
   "source": [
    "print(gridsearch.best_params_)\n",
    "print(gridsearch.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix for Gradient Boosting Classifier\n",
      "[[ 33  52]\n",
      " [ 12 300]]\n",
      "Score 83.88\n"
     ]
    }
   ],
   "source": [
    "# Boosting\n",
    "gbi = GradientBoostingClassifier(learning_rate = 0.2,\n",
    "                                max_depth = 3,\n",
    "                                random_state = 0)\n",
    "\n",
    "gbi.fit(X_train, y_train)\n",
    "predgbi = gbi.predict(X_test)\n",
    "print(\"Confusion Matrix for Gradient Boosting Classifier\")\n",
    "print(confusion_matrix(y_test,predgbi))\n",
    "print(\"Score\", round(accuracy_score(y_test,predgbi)*100,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient Boosting Accuracy 0.8387909319899244\n"
     ]
    }
   ],
   "source": [
    "print(\"Gradient Boosting Accuracy\", metrics.accuracy_score(y_test, predgbi))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus2 = []\n",
    "rev = re.sub(\"[^a-zA-z]\", \" \",text)\n",
    "rev = rev.lower()\n",
    "rev = rev.split()\n",
    "ps = PorterStemmer()\n",
    "rev = [ps.stem(word) for word in rev if not word in set(stopwords.words(\"english\"))]\n",
    "rev = \" \".join(rev)\n",
    "corpus2.append(rev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict the sentiment of this comment\n",
    "text = \"The lobster is so delicious. The decor and atmosphere are fantastic.  It's overall a very pleasant expirience.  Will definitely come again!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2 = CountVectorizer(max_features = 1000)\n",
    "X2 = cv.fit_transform(corpus + corpus2).toarray()\n",
    "my = X2[-1].reshape(1,-1)\n",
    "result = gbi.predict(my)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Good\n"
     ]
    }
   ],
   "source": [
    "if result == 1:\n",
    "    print(\"Good\")\n",
    "else:\n",
    "    print(\"Bad\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
